output: default
groups:
  HrngV7:
    name: Aggregate by msg
    description: Using somewhat normalized message text, aggregate if the component and
      level are in the lookup
    index: 3
asyncFuncTimeout: 1000
functions:
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: >
        Drop some events, aggregate others, and allow others through (mostly)
        unharmed. See README for how to enable the Pack.


        First, we'll drop anything with a log level of DEBUG or TRACE. Sometimes they get turned on and flood your internal indexes.


        Next, we'll extract the component and the message. A temp msg field will be created by removing numbers from the text. We'll use this new msg field to aggregate if the component and log level are in the `components_supression.csv` lookup. We've provided some suggested targets. Change as you see fit. Suppressed events will include a ` repeated=#` tag appended to the end, and a window index time field for the timeframe the aggregation happened in. Eg, 30 seconds.


        Next, and optionally, the timestamp is trimmed from _raw.


        Finally, and optionally, we trim the source field down to just `./splunkd.log`. Every little bit helps :-)
  - id: regex_extract
    filter: "true"
    disabled: false
    conf:
      source: _raw
      iterations: 100
      overwrite: false
      regex: /^\S+\s\S+\s[-+0-9]+\s(?<__level>\w+)\s+(?<__component>\S+)\s(?<__msg>.*)/
    description: temp fields, used in later steps
  - id: drop
    filter: /(DEBUG|TRACE)/.test(__level)
    disabled: false
    conf: {}
    final: true
  - id: eval
    filter: __msg
    disabled: null
    conf:
      add:
        - name: __msgcleaned
          value: __msg.replace(/\d+/g,"X")
    description: Create a copy of msg without numbers to "normalize it" for aggregation
      purposes
    groupId: HrngV7
  - id: aggregation
    filter: C.Lookup('components_suppression.csv').match(`${__component}-${__level}`)
    disabled: false
    conf:
      passthrough: false
      preserveGroupBys: false
      sufficientStatsOnly: false
      metricsMode: false
      timeWindow: 300s
      aggregations:
        - count()
        - last(_raw).as('_raw')
        - last(source).as('source')
        - last(sourcetype).as('sourcetype')
        - last(index).as('index')
        - last(_time).as('_time')
      cumulative: false
      flushOnInputClose: true
      groupbys:
        - host
        - __msgcleaned
        - __level
        - __component
      add:
        - name: __agged
          value: "true"
        - name: _raw
          value: "`${_raw}, repeated=${count}` "
    description: If the component-loglevel is in the lookup, we're aggregating this log.
      Will only show the last, with a count of how many times int he last 5
      minutes
    final: false
    groupId: HrngV7
  - id: eval
    filter: __agged
    disabled: null
    conf:
      add:
        - name: window
          value: endtime-starttime
      remove:
        - starttime
        - endtime
        - count
    groupId: HrngV7
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: "[optional] _time already exists, lose the timestamp in _raw (breaks
        default field extracts)"
  - id: eval
    filter: _time
    disabled: false
    conf:
      add:
        - name: _raw
          value: _raw.replace(/^\S+\s\S+\s[-+0-9]+ /,'')
    description: Drop time info
  - id: comment
    filter: "true"
    disabled: null
    conf:
      comment: "[optional] Reduce source field to just the filename"
  - id: eval
    filter: "true"
    disabled: null
    conf:
      add:
        - name: source
          value: source.replace(/.*[\\/]/,'./')
    description: Small reduction in disk hit
